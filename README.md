# llm-infer
Benchmark and identify the best ways to speedup LLM inference.

Resources

[llm-hacker](https://github.com/fastai/lm-hackers/blob/main/lm-hackers.ipynb)

[coursera-llm](https://github.com/Ryota-Kawamura/Generative-AI-with-LLMs/tree/main)

[fine-tune-mistral](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Mistral)

[prompt-engineering-guide](https://www.promptingguide.ai/) : This has mistral specific details.

[Coursera prompt-engineering course](https://github.com/ksm26/chatGPT-Prompt-Engineering-for-Developers/tree/main)

[another prompt engineering course](https://github.com/mikeffendii/Building-Systems-with-the-ChatGPT-API)


For structuring experimets(mlops): https://github.com/vin136/MLOPS
