# llm-infer
Benchmark and identify the best ways to speedup LLM inference.

Resources

[llm-hacker]?(https://github.com/fastai/lm-hackers/blob/main/lm-hackers.ipynb)

[coursera-llm](https://github.com/Ryota-Kawamura/Generative-AI-with-LLMs/tree/main)

[fine-tune-mistral](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/Mistral)
